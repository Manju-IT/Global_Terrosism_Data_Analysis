{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete!\n",
      "Original columns: 41\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 121\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaning complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns_to_keep)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcount(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemaining columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('glo.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. Handle Missing Values\n",
    "# =====================================================================\n",
    "\n",
    "# List of columns to keep based on your specification\n",
    "columns_to_keep = [\n",
    "    'eventid', 'iyear', 'imonth', 'iday', 'approxdate', 'extended',\n",
    "    'resolution', 'country', 'country_txt', 'region', 'region_txt',\n",
    "    'provstate', 'city', 'latitude', 'longitude', 'specificity',\n",
    "    'vicinity', 'location', 'crit1', 'crit2', 'crit3', 'doubtterr',\n",
    "    'alternative', 'alternative_txt', 'multiple', 'success', 'suicide',\n",
    "    'attacktype1', 'attacktype1_txt', 'attacktype2', 'attacktype2_txt',\n",
    "    'attacktype3', 'attacktype3_txt', 'targtype1', 'targtype1_txt',\n",
    "    'targsubtype1', 'targsubtype1_txt', 'corp1', 'target1', 'natlty1',\n",
    "    'natlty1_txt'\n",
    "]\n",
    "\n",
    "# Filter only the specified columns\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Drop columns with >70% missing values\n",
    "threshold = len(df) * 0.30  # Keep columns with at least 30% data\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# =====================================================================\n",
    "# 2. Handle Date-related Columns\n",
    "# =====================================================================\n",
    "\n",
    "# Fix invalid dates\n",
    "df['iday'] = df['iday'].replace(0, 1)\n",
    "df['imonth'] = df['imonth'].replace(0, 1)\n",
    "\n",
    "# Create date column\n",
    "df['date'] = pd.to_datetime(\n",
    "    df['iyear'].astype(str) + '-' + \n",
    "    df['imonth'].astype(str) + '-' + \n",
    "    df['iday'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Clean Categorical Data\n",
    "# =====================================================================\n",
    "\n",
    "categorical_cols = [\n",
    "    'country_txt', 'region_txt', 'provstate', 'city',\n",
    "    'attacktype1_txt',\n",
    "    'targtype1_txt', 'targsubtype1_txt', 'natlty1_txt'\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # Fill NA and convert to category\n",
    "    df[col] = df[col].fillna('Unknown').astype('category')\n",
    "    \n",
    "# =====================================================================\n",
    "# 4. Clean Numerical Data\n",
    "# =====================================================================\n",
    "\n",
    "numerical_cols = [\n",
    "    'latitude', 'longitude', 'specificity',\n",
    "    'crit1', 'crit2', 'crit3', 'multiple', 'success', 'suicide'\n",
    "]\n",
    "\n",
    "for col in numerical_cols:\n",
    "    # Fill NA with 0 for binary/coordinate columns\n",
    "    df[col] = df[col].fillna(0).astype(float)\n",
    "\n",
    "# Handle geographical outliers\n",
    "df['latitude'] = df['latitude'].clip(-90, 90)\n",
    "df['longitude'] = df['longitude'].clip(-180, 180)\n",
    "\n",
    "# =====================================================================\n",
    "# 5. Clean Text Data\n",
    "# =====================================================================\n",
    "\n",
    "text_cols = ['target1', 'corp1', 'location']\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].str.strip().str.title().replace(\n",
    "        ['Unknown', 'Unknown Group'], np.nan\n",
    "    )\n",
    "\n",
    "# =====================================================================\n",
    "# 6. Handle Special Values\n",
    "# =====================================================================\n",
    "\n",
    "# Replace placeholder values\n",
    "df.replace({\n",
    "    -9: np.nan,\n",
    "    -99: np.nan,\n",
    "    -999: np.nan\n",
    "}, inplace=True)\n",
    "\n",
    "# =====================================================================\n",
    "# 7. Final Cleaning\n",
    "# =====================================================================\n",
    "\n",
    "# Drop low-value columns\n",
    "cols_to_drop = [\n",
    "    'approxdate', 'resolution', 'doubtterr',\n",
    "    'alternative', 'alternative_txt', 'natlty1'\n",
    "]\n",
    "df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(subset=['eventid'], keep='first', inplace=True)\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('cleaned_terrorism_data.csv', index=False)\n",
    "\n",
    "print(\"Cleaning complete!\")\n",
    "print(f\"Original columns: {len(columns_to_keep)}\")\n",
    "print(f\"Final columns: {len(df.columns)}\")\n",
    "print(f\"Remaining columns:\\n{df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'casualties'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'casualties'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m180\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Cap casualty numbers at 99th percentile\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m casualty_cap \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcasualties\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.99\u001b[39m)\n\u001b[0;32m     87\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasualties\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasualties\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m casualty_cap, casualty_cap, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasualties\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# =====================================================================\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# 8. Final Cleaning\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# =====================================================================\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Drop unnecessary columns\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'casualties'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('glo.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "\n",
    "# # =====================================================================\n",
    "# # 1. Handle Missing Values\n",
    "# # =====================================================================\n",
    "\n",
    "# # Drop columns with >60% missing values\n",
    "# threshold = len(df) * 0.60\n",
    "# df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# # Fill categorical missing values\n",
    "# categorical_cols = ['region_txt', 'country_txt', 'attacktype1_txt', 'targtype1_txt']\n",
    "# for col in categorical_cols:\n",
    "#     df.fillna({col:'Unknown'}, inplace=True)\n",
    "\n",
    "# # Fill numerical missing values\n",
    "# numerical_cols = ['nkill', 'nwound', 'latitude', 'longitude']\n",
    "# for col in numerical_cols:\n",
    "#     df.fillna({col:0}, inplace=True)\n",
    "\n",
    "# # Handle date-related columns\n",
    "# df['iday'] = df['iday'].replace(0, 1)  # Replace 0 days with 1\n",
    "# df['imonth'] = df['imonth'].replace(0, 1)  # Replace 0 months with 1\n",
    "\n",
    "# # =====================================================================\n",
    "# # 2. Data Type Conversion\n",
    "# # =====================================================================\n",
    "\n",
    "# # Convert dates to datetime format\n",
    "# date_cols = ['iyear', 'imonth', 'iday']\n",
    "# df['date'] = pd.to_datetime(df[date_cols].astype(str).agg('-'.join, axis=1), errors='coerce')\n",
    "\n",
    "# # Convert categoricals to proper type\n",
    "# df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "# # =====================================================================\n",
    "# # 3. Handle Duplicates\n",
    "# # =====================================================================\n",
    "\n",
    "# # Remove exact duplicates\n",
    "# df.drop_duplicates(subset=['eventid'], keep='first', inplace=True)\n",
    "\n",
    "# # =====================================================================\n",
    "# # 4. Standardize Text Data\n",
    "# # =====================================================================\n",
    "\n",
    "# # Clean text columns\n",
    "# text_cols = ['city', 'target1', 'targsubtype1_txt','corp1']\n",
    "# for col in text_cols:\n",
    "#     df[col] = df[col].str.strip().str.title().replace('Unknown', np.nan)\n",
    "\n",
    "# # =====================================================================\n",
    "# # 5. Handle Special Values\n",
    "# # =====================================================================\n",
    "\n",
    "# # Replace placeholder values\n",
    "# df.replace({-9: np.nan, -99: np.nan}, inplace=True)\n",
    "\n",
    "# # Replace text placeholders only in text columns (not categorical columns)\n",
    "# text_cols = ['city', 'target1', 'targsubtype1_txt', 'corp1']\n",
    "# text_replacements = {'Unknown': np.nan, 'Unknown Group': np.nan}\n",
    "# df[text_cols] = df[text_cols].replace(text_replacements)\n",
    "# # =====================================================================\n",
    "# # 6. Feature Engineering\n",
    "# # =====================================================================\n",
    "\n",
    "# # # Create casualty feature\n",
    "# # df['casualties'] = df['nkill'] + df['nwound']\n",
    "\n",
    "# # # Create decade feature\n",
    "# # df['decade'] = (df['iyear'] // 10) * 10\n",
    "\n",
    "# # =====================================================================\n",
    "# # 7. Outlier Handling\n",
    "# # =====================================================================\n",
    "\n",
    "# # Handle geographical outliers\n",
    "# df['latitude'] = df['latitude'].clip(-90, 90)\n",
    "# df['longitude'] = df['longitude'].clip(-180, 180)\n",
    "\n",
    "# # Cap casualty numbers at 99th percentile\n",
    "# casualty_cap = df['casualties'].quantile(0.99)\n",
    "# df['casualties'] = np.where(df['casualties'] > casualty_cap, casualty_cap, df['casualties'])\n",
    "\n",
    "# # =====================================================================\n",
    "# # 8. Final Cleaning\n",
    "# # =====================================================================\n",
    "\n",
    "# # Drop unnecessary columns\n",
    "# cols_to_drop = ['approxdate', 'resolution', 'doubtterr', 'alternative', 'related']\n",
    "# df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "# # Reset index\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Save cleaned data\n",
    "# df.to_csv('cleaned_global_terrorism.csv', index=False)\n",
    "\n",
    "# print(\"Data cleaning complete!\")\n",
    "# print(f\"Original shape: {df.shape}\")\n",
    "# print(f\"Cleaned shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_12968\\77901409.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'nkill'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'nkill'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m numerical_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnkill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnwound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numerical_cols:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miday\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'nkill'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('glo.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. Handle Missing Values\n",
    "# =====================================================================\n",
    "threshold = len(df) * 0.60\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "categorical_cols = ['region_txt', 'country_txt', 'attacktype1_txt', 'targtype1_txt']\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "numerical_cols = ['nkill', 'nwound', 'latitude', 'longitude']\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(0, inplace=True)\n",
    "\n",
    "df['iday'] = df['iday'].replace(0, 1)\n",
    "df['imonth'] = df['imonth'].replace(0, 1)\n",
    "\n",
    "# =====================================================================\n",
    "# 2. Data Type Conversion\n",
    "# =====================================================================\n",
    "date_cols = ['iyear', 'imonth', 'iday']\n",
    "df['date'] = pd.to_datetime(df[date_cols].astype(str).agg('-'.join, axis=1), errors='coerce')\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Handle Duplicates\n",
    "# =====================================================================\n",
    "df.drop_duplicates(subset=['eventid'], keep='first', inplace=True)\n",
    "\n",
    "# =====================================================================\n",
    "# 4. Standardize Text Data\n",
    "# =====================================================================\n",
    "text_cols = ['city', 'target1', 'targsubtype1_txt', 'corp1']\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].str.strip().str.title().replace('Unknown', np.nan)\n",
    "\n",
    "# =====================================================================\n",
    "# 5. Handle Special Values (Corrected Section)\n",
    "# =====================================================================\n",
    "df.replace({-9: np.nan, -99: np.nan}, inplace=True)  # Numerical replacements\n",
    "text_replacements = {'Unknown': np.nan, 'Unknown Group': np.nan}\n",
    "df[text_cols] = df[text_cols].replace(text_replacements)  # Text column replacements\n",
    "\n",
    "# =====================================================================\n",
    "# 6-8. Remaining Steps (Unchanged)\n",
    "# =====================================================================\n",
    "df['casualties'] = df['nkill'] + df['nwound']\n",
    "df['decade'] = (df['iyear'] // 10) * 10\n",
    "\n",
    "df['latitude'] = df['latitude'].clip(-90, 90)\n",
    "df['longitude'] = df['longitude'].clip(-180, 180)\n",
    "\n",
    "casualty_cap = df['casualties'].quantile(0.99)\n",
    "df['casualties'] = np.where(df['casualties'] > casualty_cap, casualty_cap, df['casualties'])\n",
    "\n",
    "cols_to_drop = ['approxdate', 'resolution', 'doubtterr', 'alternative', 'related']\n",
    "df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_csv('cleaned_global_terrorism.csv', index=False)\n",
    "\n",
    "print(\"Data cleaning complete!\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
